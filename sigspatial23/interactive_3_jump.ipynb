{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# for fitting empirical distributions for radius of gyration and jump length\n",
    "import powerlaw\n",
    "\n",
    "# for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# trackintel -> the functions will be imported with full names\n",
    "import trackintel as ti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for better printing and visualizing\n",
    "\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "matplotlib.rcParams[\"xtick.labelsize\"] = 13\n",
    "matplotlib.rcParams[\"ytick.labelsize\"] = 13\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data dir from the config file -> default stored in Data/Geolife/Data folder\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"paths.json\")\n",
    "with open(DATA_DIR) as json_file:\n",
    "    CONFIG = json.load(json_file)\n",
    "\n",
    "save_dir = os.path.join(\"..\", CONFIG[\"data_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Geolife data\n",
    "Trackintel provides a function [read_geolife](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_geolife) to directly load [Geolife](https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/) dataset into the trackintel positionfixes. For the tutorial and interactive section, we provided you a sample dataset with 20 selected users from the geolife dataset. This can be directly loaded from the `save_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:09<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "pfs, mode_labels = ti.io.read_geolife(save_dir, print_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading your own data\n",
    "Trackintel provides an I/O module for accessing movement data and storing intermediate or final results in a file or database. Three methods for converting movement data with attached attribute information to Trackintel-compatible formats are provided:\n",
    "1) reading from Pandas Dataframes and Geopandas Geodataframes (**recommended**)\n",
    "2) reading and writing from CSV file formats\n",
    "3) reading and storing from PostgreSQL databases with PostGIS extension. Check the [input/output](https://trackintel.readthedocs.io/en/latest/modules/io.html) module for more information. \n",
    "\n",
    "An important consideration before loading data is to find the appropriate movement level for your data. Depending on the semantics of the data, you should call different reading functions, e.g., [read_positionfixes_csv](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_positionfixes_csv) or [read_staypoints_csv](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_staypoints_csv). We provide a reference of the different data types in the figure below:\n",
    "\n",
    "![Trackintel data support](prepare/trackintel_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use ti.read_positionfixes_csv() or ti.read_staypoints_csv() for loading your data. Check the documentation for the required input parameters\n",
    "# selected_pfs = ti.read_positionfixes_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Jump length\n",
    "\n",
    "Desired outcome with geolife sample data:\n",
    "\n",
    "![Jump length result](prepare/jump_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate staypoints\n",
    "Jump length measures the distance between consecutive stays. This definition corresponds to trackintel's **staypoint** data model. The following code is to generate staypoints from the raw positionfixes with the trackintel function [generate_staypoints](https://trackintel.readthedocs.io/en/latest/modules/preprocessing.html#trackintel.preprocessing.generate_staypoints). Click on the link to check the documentation on the meaning of the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yehong/mambaforge/envs/reprotrack/lib/python3.9/site-packages/trackintel/preprocessing/positionfixes.py:113: UserWarning: 1690 duplicates were dropped from your positionfixes. Dropping duplicates is recommended but can be prevented using the 'exclude_duplicate_pfs' flag.\n",
      "  warnings.warn(warn_str)\n",
      "100%|██████████| 20/20 [00:03<00:00,  6.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate staypoints from positionfixes with generate_staypoints() function, check and specify the parameters\n",
    "pfs, sp = pfs.generate_staypoints(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate jump length\n",
    "Trackintel provide implementations for calculating the jumplength with staypoints that have geometry column. Check out the function [trackintel.analysis.metrics.jump_length()](https://trackintel.readthedocs.io/en/latest/modules/analysis.html#trackintel.analysis.jump_length). The output of the function is available as a series that shares the same index as the input dataframe. This ensures that we can use a column to hold the result (e.g., using `sp[\"jumplength\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call jump_length() function provided by trackintel\n",
    "sp[\"jumplength\"] = ...\n",
    "\n",
    "# TODO: transform jump length from pandas series to np.array. Note to filter the nan values at the end of each user record\n",
    "jumplength_arr = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with powerlaw library \n",
    "The [powerlaw](https://github.com/jeffalstott/powerlaw) package provides functionalities to fit power-law, truncated power law, and log normal distributions to the original data. It also provides functionalities to plot all the fitted distributions on the same plot. We use the powerlaw package to visualize the radius of calculation result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "jp = jumplength_arr[jumplength_arr>100]\n",
    "\n",
    "# fit power law\n",
    "fit = powerlaw.Fit(jp, xmin=100)\n",
    "\n",
    "# plotting\n",
    "powerlaw.plot_pdf(jp, label=\"count\")\n",
    "fit.power_law.plot_pdf(linestyle=\"--\", label=\"powerlaw fit\")\n",
    "fit.truncated_power_law.plot_pdf(linestyle=\"--\", label=\"truncated power law\")\n",
    "fit.lognormal.plot_pdf(linestyle=\"--\", label=\"lognormal fit\")\n",
    "\n",
    "\n",
    "plt.legend(prop={\"size\": 13})\n",
    "plt.xlabel(\"$\\Delta r\\,(m)$\", fontsize=16)\n",
    "plt.ylabel(\"$P(\\Delta r)$\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9597c3010ccf3b8705a75eca2c37e93b64c1720a9347287e0e23a990d1a82733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
