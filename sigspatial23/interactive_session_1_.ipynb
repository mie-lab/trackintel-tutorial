{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprotrack - Interactive session\n",
    "For this session, we have collected five different reproducibility/replication challenges that you can solve in any order you want. For the challenges we have provided you with a subsample of the Geolife dataset but you can also use your own data. \n",
    "\n",
    "1. Tracking quality assessment\n",
    "2. Travel mode split\n",
    "3. Replicate mobility scaling laws - Jump length\n",
    "4. Replicate mobility scaling laws - Radius of gyration\n",
    "5. Context integration with OSM data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle as pickle\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for fitting empirical distributions for radius of gyration and jump length\n",
    "import powerlaw\n",
    "# for fetching osm data\n",
    "import osmnx as ox\n",
    "\n",
    "# for visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# trackintel -> the functions will be imported with full names\n",
    "import trackintel as ti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for better printing and visualizing\n",
    "\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 300\n",
    "matplotlib.rcParams[\"xtick.labelsize\"] = 13\n",
    "matplotlib.rcParams[\"ytick.labelsize\"] = 13\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data dir from the config file -> default stored in Data/Geolife/Data folder\n",
    "\n",
    "DATA_DIR = os.path.join(\"..\", \"paths.json\")\n",
    "with open(DATA_DIR) as json_file:\n",
    "    CONFIG = json.load(json_file)\n",
    "\n",
    "save_dir = os.path.join(\"..\", CONFIG[\"data_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Geolife data\n",
    "Trackintel provides a function [read_geolife](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_geolife) to directly load [Geolife](https://www.microsoft.com/en-us/research/publication/geolife-gps-trajectory-dataset-user-guide/) dataset into the trackintel positionfixes. For the tutorial and interactive section, we provided you a sample dataset with 20 selected users from the geolife dataset. This can be directly loaded from the `save_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:28<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pfs, mode_labels = ti.io.read_geolife(save_dir, print_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading your own data\n",
    "Trackintel provides an I/O module for accessing movement data and storing intermediate or final results in a file or database. Three methods for converting movement data with attached attribute information to Trackintel-compatible formats are provided:\n",
    "1) reading from Pandas Dataframes and Geopandas Geodataframes (**recommended**)\n",
    "2) reading and writing from CSV file formats\n",
    "3) reading and storing from PostgreSQL databases with PostGIS extension. Check the [input/output](https://trackintel.readthedocs.io/en/latest/modules/io.html) module for more information. \n",
    "\n",
    "An important consideration before loading data is to find the appropriate movement level for your data. Depending on the semantics of the data, you should call different reading functions, e.g., [read_positionfixes_csv](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_positionfixes_csv) or [read_staypoints_csv](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.read_staypoints_csv). We provide a reference of the different data types in the figure below:\n",
    "\n",
    "![Trackintel data support](prepare/trackintel_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use ti.read_positionfixes_csv() or ti.read_staypoints_csv() for loading your data. Check the documentation for the required input parameters\n",
    "# selected_pfs = ti.read_positionfixes_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate tracking quality\n",
    "Trackintel provides functions to assist in examining the tracking quality of users from the temporal perspective. We use temporal tracking coverage, defined as the proportion of time the user's whereabouts are recorded, to measure tracking quality. As positionfixes contain only absolute timestamps for each record, one needs to define how long a time gap shall be to regard a user's whereabouts are missing. This design choice can be specified when aggregating positonfixes into staypoints and trips, using the respective temporal parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate staypoints and trips \n",
    "Select the temporal parameters to reflect your design choice of a `time gap`.\n",
    "\n",
    "Tasks: \n",
    "- create staypoints\n",
    "- add activities to staypoints\n",
    "- create triplegs\n",
    "- create trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\reprotrack\\lib\\site-packages\\trackintel\\preprocessing\\positionfixes.py:113: UserWarning: 1690 duplicates were dropped from your positionfixes. Dropping duplicates is recommended but can be prevented using the 'exclude_duplicate_pfs' flag.\n",
      "  warnings.warn(warn_str)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:13<00:00,  1.50it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate staypoints, triplegs and trips\n",
    "pfs, sp = pfs.generate_staypoints(gap_threshold=24 * 60, include_last=True, print_progress=True, dist_threshold=200, time_threshold=30, n_jobs=-1)\n",
    "\n",
    "# create activity flag\n",
    "sp = sp.create_activity_flag(method=\"time_threshold\", time_threshold=25)\n",
    "\n",
    "# generate triplegs\n",
    "pfs, tpls = pfs.generate_triplegs(sp, gap_threshold=15, print_progress=True)\n",
    "\n",
    "# generate trips\n",
    "sp, tpls, trips = sp.generate_trips(tpls, add_geometry=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tracking quality\n",
    "We then concatenate staypoints and triplegs to obtain a continues timeline for measuring the tracking coverage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge trips and staypoints\n",
    "df_all = pd.concat([sp, trips])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trackintel provides the [trackintel.analysis.temporal_tracking_quality](https://trackintel.readthedocs.io/en/latest/modules/analysis.html#trackintel.analysis.temporal_tracking_quality) function to measure the temporal tracking coverage. For the function to work, users need to specify a `granularity` (i.e., to what time extent is the tracking data compared to?). Check the documentations and decide on a desired granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quality\n",
    "total_quality = ti.analysis.temporal_tracking_quality(df_all, granularity=\"all\")\n",
    "\n",
    "boxplot = total_quality.boxplot(column=\"quality\", figsize=(5, 5))\n",
    "\n",
    "boxplot.set_xticklabels([])\n",
    "\n",
    "plt.xlabel(\"Tracking quality\", fontsize=16)\n",
    "plt.ylabel(\"Proportion\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality by week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quality\n",
    "week_quality = ti.analysis.temporal_tracking_quality(df_all, granularity=\"week\")\n",
    "\n",
    "week_quality_user = week_quality.loc[week_quality[\"quality\"] != 0].groupby(\"week_monday\", as_index=False)[\"quality\"].median()\n",
    "\n",
    "# construct the index\n",
    "week_quality_user.set_index(\"week_monday\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(week_quality_user.index, week_quality_user['quality'], label=\"Geolife subset\", color=colors[0])\n",
    "ax.set_ylabel(\"Tracking Quality by Month (Median)\", fontsize=16)\n",
    "ax.set_xlabel(\"\", fontsize=16)\n",
    "\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=14))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=9))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "ax.set_ylim([0, 1.09])\n",
    "ax.legend(prop={'size': 12}, loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quality\n",
    "day_quality = ti.analysis.temporal_tracking_quality(df_all, granularity=\"day\")\n",
    "\n",
    "day_quality_user = day_quality.loc[day_quality[\"quality\"] != 0].groupby(\"day\", as_index=False)[\"quality\"].median()\n",
    "# construct the index\n",
    "day_quality_user.set_index(\"day\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(day_quality_user.index, day_quality_user['quality'], label=\"Geolife subset\", color=colors[0])\n",
    "ax.set_ylabel(\"Tracking Quality by Day (Median)\", fontsize=16)\n",
    "ax.set_xlabel(\"\", fontsize=16)\n",
    "\n",
    "ax.xaxis.set_minor_locator(mdates.DayLocator(interval=14))\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=9))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "ax.set_ylim([0, 1.09])\n",
    "ax.legend(prop={'size': 12}, loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality by weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quality\n",
    "weekday_quality = ti.analysis.temporal_tracking_quality(df_all, granularity=\"weekday\")\n",
    "\n",
    "weekday_quality_user = weekday_quality.loc[weekday_quality[\"quality\"] != 0].groupby(\"weekday\", as_index=False)[\"quality\"].median()\n",
    "\n",
    "weekday_quality_user.set_index(\"weekday\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(weekday_quality_user.index, weekday_quality_user['quality'], label=\"Geolife subset\", color=colors[0])\n",
    "ax.set_ylabel(\"Tracking Quality by Weekday (Median)\", fontsize=15)\n",
    "ax.set_xlabel(\"\", fontsize=15)\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "ax.set_ylim([0, 1.09])\n",
    "ax.set_xticks(np.arange(7), labels= [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "\n",
    "ax.legend(prop={'size': 12}, loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get quality\n",
    "hour_quality = ti.analysis.temporal_tracking_quality(df_all, granularity=\"hour\")\n",
    "\n",
    "hour_quality_user = hour_quality.loc[hour_quality[\"quality\"] != 0].groupby(\"hour\", as_index=False)[\"quality\"].median()\n",
    "\n",
    "hour_quality_user.set_index(\"hour\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax.plot(hour_quality_user.index, hour_quality_user['quality'], label=\"Geolife subset\", color=colors[0])\n",
    "ax.set_ylabel(\"Tracking Quality by Hour (Median)\", fontsize=15)\n",
    "ax.set_xlabel(\"\", fontsize=15)\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "\n",
    "ax.set_ylim([0, 1.09])\n",
    "ax.set_xticks(np.arange(24))\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=15)\n",
    "\n",
    "ax.legend(prop={'size': 12}, loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Calculate the travel mode split\n",
    "Travel mode choices are formed due to the everyday needs and constraints of individuals and are influenced by travel-related factors such as cost, time, accessibility, and comfort. It is, therefore, not uncommon for mobility systems to be evaluated and compared based on the current modal splits of the overall population. Trackintel provides a series of travel mode-related functions to assist in mode analysis of individual movement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach mode labels to triplegs - true labels and mode detection based on speed\n",
    "- Attach labels provided by Geolife using the Trackintel function [geolife_add_modes_to_triplegs](https://trackintel.readthedocs.io/en/latest/modules/io.html#trackintel.io.geolife_add_modes_to_triplegs)\n",
    "- Impute mode labels based on speed using the Trackintel function [predict_transport_mode](geolife_add_modes_to_triplegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the true mode labels to triplegs, with the help of trackintel functions \n",
    "tpls = ti.io.geolife_add_modes_to_triplegs(tpls, selected_mode_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the mode of the other triplegs based on speed \n",
    "tpls[\"pred_mode\"] = ti.analysis.predict_transport_mode(tpls)[\"mode\"]\n",
    "tpls.loc[tpls[\"mode\"].isna(), \"mode\"] = tpls.loc[tpls[\"mode\"].isna(), \"pred_mode\"]\n",
    "tpls.drop(columns={\"pred_mode\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_to_category = {\n",
    "    \"fast_mobility\": \"fast\",\n",
    "    \"car\": \"motorized\",\n",
    "    \"bus\": \"motorized\",\n",
    "    \"taxi\": \"motorized\",\n",
    "    \"ecar\": \"motorized\",\n",
    "    \"motorized_mobility\": \"motorized\",\n",
    "    \"bike\": \"slow\",\n",
    "    \"walk\": \"slow\",\n",
    "    \"slow_mobility\": \"slow\",\n",
    "}\n",
    "\n",
    "# change mode labels with the above mapping\n",
    "tpls[\"mode\"] = tpls[\"mode\"].map(mode_to_category)\n",
    "tpls.dropna(subset=[\"mode\"], inplace=True)\n",
    "tpls[\"mode\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize modal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count\n",
    "modal_split_count = ti.analysis.calculate_modal_split(tpls, freq=\"M\", metric=\"count\", per_user=False, norm=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = ti.plot_modal_split(\n",
    "    modal_split_count,\n",
    "    date_fmt_x_axis=\"%Y-%m\",\n",
    "    y_label=\"Percentage of count\",\n",
    "    skip_xticks=2,\n",
    "    n_col_legend=4,\n",
    "    fig=fig,\n",
    "    axis=ax,\n",
    "    borderaxespad=2,\n",
    ")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance\n",
    "modal_split_distance = ti.analysis.calculate_modal_split(tpls, freq=\"M\", metric=\"distance\", per_user=False, norm=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = ti.plot_modal_split(\n",
    "    modal_split_distance,\n",
    "    date_fmt_x_axis=\"%Y-%m\",\n",
    "    y_label=\"Percentage of distance\",\n",
    "    skip_xticks=2,\n",
    "    n_col_legend=4,\n",
    "    fig=fig,\n",
    "    axis=ax,\n",
    "    borderaxespad=2,\n",
    ")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "modal_split_duration = ti.analysis.calculate_modal_split(tpls, freq=\"M\", metric=\"duration\", per_user=False, norm=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = ti.plot_modal_split(\n",
    "    modal_split_duration,\n",
    "    date_fmt_x_axis=\"%Y-%m\",\n",
    "    y_label=\"Percentage of duration\",\n",
    "    skip_xticks=2,\n",
    "    n_col_legend=4,\n",
    "    fig=fig,\n",
    "    axis=ax,\n",
    "    borderaxespad=2,\n",
    ")\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Jump length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate staypoints\n",
    "Jump length measures the distance between consecutive stays. This definition corresponds to trackintel's **staypoint** data model. The following code is to generate staypoints from the raw positionfixes with the trackintel function [generate_staypoints](https://trackintel.readthedocs.io/en/latest/modules/preprocessing.html#trackintel.preprocessing.generate_staypoints). Click on the link to check the documentation on the meaning of the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pfs, sp = selected_pfs.generate_staypoints(gap_threshold=24 * 60, include_last=True, print_progress=True, dist_threshold=200, time_threshold=30, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate jump length\n",
    "Trackintel provide implementations for calculating the jumplength with staypoints that have geometry column. Check out the function [trackintel.analysis.metrics.jump_length()](https://trackintel.readthedocs.io/en/latest/modules/analysis.html#trackintel.analysis.jump_length). The output of the function is available as a series that shares the same index as the input dataframe. This ensures that we can use a column to hold the result (e.g., using `sp[\"jumplength\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp[\"jumplength\"] = ti.analysis.jump_length(sp)\n",
    "jumplength_arr = sp.dropna(subset=[\"jumplength\"])[\"jumplength\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with powerlaw library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "\n",
    "# fit power law\n",
    "xmin = 100\n",
    "fit = powerlaw.Fit(jumplength_arr[jumplength_arr>xmin], xmin=xmin)\n",
    "\n",
    "# plotting\n",
    "powerlaw.plot_pdf(jumplength_arr[jumplength_arr>xmin], label=\"count\")\n",
    "fit.power_law.plot_pdf(linestyle=\"--\", label=\"powerlaw fit\")\n",
    "fit.truncated_power_law.plot_pdf(linestyle=\"--\", label=\"truncated power law\")\n",
    "fit.lognormal.plot_pdf(linestyle=\"--\", label=\"lognormal fit\")\n",
    "\n",
    "xlabel = \"$\\Delta r\\,(m)$\"\n",
    "ylabel = \"$P(\\Delta r)$\"\n",
    "\n",
    "plt.legend(prop={\"size\": 13})\n",
    "plt.xlabel(xlabel, fontsize=16)\n",
    "plt.ylabel(ylabel, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate Radius of Gyration\n",
    "\n",
    "- You need staypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate staypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfs, sp = selected_pfs.generate_staypoints(gap_threshold=24 * 60, include_last=True, print_progress=True, dist_threshold=200, time_threshold=30, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate radius of gyration with trackintel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_count = ti.analysis.radius_gyration(sp, method=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp[\"duration\"] = (sp[\"finished_at\"] - sp[\"started_at\"])\n",
    "rg_duration = ti.analysis.radius_gyration(sp, method=\"duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize with powerlaw package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "\n",
    "# fit power law\n",
    "xmin = 100\n",
    "fit = powerlaw.Fit(rg_duration, xmin=xmin)\n",
    "\n",
    "# plotting\n",
    "powerlaw.plot_pdf(rg_count, label=\"count\")\n",
    "powerlaw.plot_pdf(rg_duration, label=\"duration\")\n",
    "fit.power_law.plot_pdf(linestyle=\"--\", label=\"powerlaw fit of duration\")\n",
    "fit.truncated_power_law.plot_pdf(linestyle=\"--\", label=\"truncated power law of duration\")\n",
    "fit.lognormal.plot_pdf(linestyle=\"--\", label=\"lognormal fit of duration\")\n",
    "\n",
    "xlabel = \"$Rg$ (m)\"\n",
    "ylabel = \"$P(Rg)$\"\n",
    "\n",
    "plt.legend(prop={\"size\": 13})\n",
    "plt.xlabel(xlabel, fontsize=16)\n",
    "plt.ylabel(ylabel, fontsize=16)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Activity prediction - trajectory context integration with OSM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate staypoints and locations\n",
    "In the trackintel definition, staypoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate staypoints, triplegs and trips\n",
    "pfs, sp = selected_pfs.generate_staypoints(gap_threshold=24 * 60, include_last=True, print_progress=True, dist_threshold=200, time_threshold=30, n_jobs=-1)\n",
    "\n",
    "# create activity flag\n",
    "sp = sp.create_activity_flag(method=\"time_threshold\", time_threshold=25)\n",
    "\n",
    "# generate locations\n",
    "## filter activity staypoints\n",
    "sp = sp.loc[sp[\"is_activity\"] == True]\n",
    "\n",
    "# generate locations\n",
    "sp, locs = sp.generate_locations(\n",
    "    epsilon=20, num_samples=1, distance_metric=\"haversine\", agg_level=\"dataset\", n_jobs=-1, print_progress=True\n",
    ")\n",
    "# filter noise staypoints\n",
    "valid_sp = sp.loc[~sp[\"location_id\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect locations\n",
    "locs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract POI from OSM and link with locations\n",
    "\n",
    "You can imagine that we can make certain statements about the reason for a trip if we know what is in the area at the destination. For example, it makes sense that we go to a university district to study, to a residential area when we go home, or to an area with many restaurants and bars to meet friends.\n",
    "\n",
    "### POI from OSM\n",
    "\n",
    "Following this intuition, we extract POIs from OpenStreetMap and link them spatially with the locations. First we define a filter, defining that OSM objects with the attribute `amenity` or `shop` are extracted from the OSM data set. These tags are very widespread in the OSM data because they describe various objects in a relatively general way. You can find out more about the OSM tags at https://wiki.openstreetmap.org/wiki/DE:Key:amenity and https://taginfo.openstreetmap.org.\n",
    "\n",
    "We use the library `osmnx` to download the newest osm data from the internet and extract certain subsets of the data as GeoDataFrame. `osmnx` is an open-source library that provides support for working with OpenStreetMap data. It enables straightforward fetching of OSM data and is still actively maintained by a group of GIS enthusiasts. Checkout the library [homepage](https://osmnx.readthedocs.io/en/stable/getting-started.html) and its [examples](https://github.com/gboeing/osmnx-examples/tree/main/notebooks).\n",
    "\n",
    "Here we define the filter below for the POIs for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_filter = {'amenity': True, 'shop': True}\n",
    "\n",
    "# apply the filter\n",
    "pois = ox.features_from_bbox(40.0920, 39.8594, 116.4410, 116.1152, custom_filter)\n",
    "\n",
    "# we now want the 'node' types\n",
    "pois = pois.iloc[pois.index.get_level_values('element_type') == \"node\"]\n",
    "\n",
    "pois.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function `plot`, which is provided by the `geopandas` library for `GeoDataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois.plot(figsize=(12, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display this data on a map and inspect it again with `.head (...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather info about POI type (combines the tag info from \"amenity\" and \"shop\").\n",
    "pois[\"poi_type\"] = pois[\"amenity\"]\n",
    "pois[\"poi_type\"] = pois[\"poi_type\"].fillna(pois[\"shop\"])\n",
    "\n",
    "# plot\n",
    "ax = pois.plot(column='poi_type', markersize=3, figsize=(12,12), legend=True, legend_kwds=dict(loc='upper left', ncol=5, bbox_to_anchor=(1, 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the DataFrame using .head(...), .columns, etc.\n",
    "pois.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to projected coordinate system, buffering and spatial join\n",
    "\n",
    "In the next step, we want to change the coordinate system from WGS 1984 to EPSG:4479, as the latter allows us to quantify distances in meters. `geopandas` offers the function `.to_crs(...)` for this operation. Then create a buffer around the sample points with the function `.buffer(dist)` and use the `gpd.sjoin(...)` function to perform a spatial join between the buffered sample points and the POI. Look at the data with `.head(...)` and check if the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buffer around locations. assume distance of 100\n",
    "epsilon = 100\n",
    "\n",
    "\n",
    "# project the data into the coordinate system EPSG:4479.\n",
    "locs_4479 = gpd.GeoDataFrame(locs.drop(columns=\"center\"), crs=\"EPSG:4326\", geometry=\"extent\")\n",
    "locs_4479 = locs_4479.to_crs('EPSG:4479')\n",
    "pois_4479 = pois.to_crs('EPSG:4479')\n",
    "\n",
    "locs_buffer = locs_4479.copy()\n",
    "\n",
    "# Create a buffer of reasonable size around the locations.\n",
    "# Remember to set a distance threshold in .buffer() (now the unit is in meters)\n",
    "locs_buffer['extent'] = locs_4479.buffer(epsilon)\n",
    "\n",
    "\n",
    "# Join the two GeoDataFrames using geopanda's sjoin function (use how='left').\n",
    "locs_pois = gpd.sjoin(locs_buffer, pois_4479, how='left')\n",
    "locs_pois = locs_pois.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine locations\n",
    "locs_pois.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now count how often a certain type of POI has occurred in the vicinity of a location and draw this in a figure. Attention: We only plot the first 20 locations for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_types_per_loc = locs_pois.groupby(['id', 'poi_type'])['id'].count().unstack('poi_type').head(20)\n",
    "poi_types_per_loc.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "plt.legend(ncol=3, loc='center left', bbox_to_anchor=(1.04, 0.5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "9597c3010ccf3b8705a75eca2c37e93b64c1720a9347287e0e23a990d1a82733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
